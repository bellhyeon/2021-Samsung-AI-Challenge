# -*- coding: utf-8 -*-
"""[Baseline]_CNN2RNN(ResNet50, LSTM).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xQQDeibN6I5czQP6r7mxLbJUKWNRPL_Z

baseline.ipynb <br>
.. ├ models <br>
.. └ data <br>
.... ├ train_sdf <br>
.... ├ dev_sdf <br>
.... ├ test_sdf <br>
.... ├ train_imgs <br>
.... ├ test_imgs <br>
.... ├ sample_train.csv <br>
.... ├ sample_test.csv <br>
.... └ sample_submission.csv <br>

## 사용 패키지
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import rdkit
from rdkit import Chem
from rdkit.Chem import Draw
from rdkit import RDLogger
RDLogger.DisableLog('rdApp.*')
from tqdm import tqdm

import torch
from torch import nn
from torchvision import models
from torch.utils.data import Dataset, DataLoader
import timm
from albumentations import (
    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip,
    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout,
    IAAAdditiveGaussianNoise, Transpose, Blur, RandomRotate90
)
from albumentations.pytorch import ToTensorV2
import random
import os
import ttach as tta


def seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True


seed_torch(seed=28)

print('numpy verison :', np.__version__)
print('pandas version :', pd.__version__)
print('opencv version :', cv2.__version__)
print('rdkit version :', rdkit.__version__)
print('torch version :', torch.__version__)

"""## 데이터 로드"""

train = pd.read_csv('../inputs/train.csv')
dev = pd.read_csv('../inputs/dev.csv')

train.head()

dev.head()

train = pd.concat([train, dev])
train['ST1_GAP(eV)'] = train['S1_energy(eV)'] - train['T1_energy(eV)']

# train['S1_energy(eV)'].hist(bins=100, alpha=0.5)
# train['T1_energy(eV)'].hist(bins=100, alpha=0.5)
# plt.show()

"""## 데이터 전처리

분자의 구조적 특성을 찾기 위해 SMILES와 분자구조 이미지를 사용하였습니다.
"""

# for idx, row in tqdm(train.iterrows()):
#     file = row['uid']
#     smiles = row['SMILES']
#     m = Chem.MolFromSmiles(smiles)
#     if m != None:
#         img = Draw.MolToImage(m, size=(300,300))
#         img.save(f'../inputs/train_imgs/{file}.png')

# sample_img = cv2.imread('../inputs/train_imgs/dev_0.png')
# plt.imshow(sample_img)
# plt.show()

"""## 하이퍼파라미터"""

device = torch.device("cuda:2")
BATCH_SIZE = 80
EPOCHS = 300
num_layers = 1
dropout_rate = 0.1
learning_rate = 2 * 1e-4
vision_pretrain = True
save_path = f'../output/models/seed_resnet200_3_best_model.pt'
img_size = 300
T_max = 10
eta_min = 1e-6



labels = train['ST1_GAP(eV)'].to_numpy()
imgs = ('../inputs/train_imgs/'+train.uid+'.png').to_numpy()

"""## 학습 데이터셋"""

from sklearn.utils import shuffle
imgs, labels = shuffle(imgs, labels, random_state=42)

train_imgs = imgs[:29500]
train_labels = labels[:29500]
val_imgs = imgs[29500:]
val_labels = labels[29500:]


class CustomDataset(Dataset):
    def __init__(self, imgs, labels=None, mode='train', transform=None):
        self.mode = mode
        self.imgs = imgs      
        if self.mode=='train':
            self.labels = np.reshape(np.array(labels), (-1, 1))
        self.transform = transform
            
    def __len__(self):
        return len(self.imgs)
    
    def __getitem__(self, i):
        img = cv2.imread(self.imgs[i])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)
        if self.transform:
            augmented = self.transform(image=img)
            img = augmented['image']

        if self.mode == 'train':
            return {
                'img' : img,
                'label' : torch.tensor(self.labels[i], dtype=torch.float32)
            }
        else:
            return {
                'img' : torch.tensor(img, dtype=torch.float32),
            }


def get_transforms(*, data):
    if data == 'train':
        return Compose([
            Rotate(30, p=.5),
            RandomRotate90(p=.5),
            Resize(img_size, img_size),
            Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
            ToTensorV2(),
        ])

    elif data == 'valid' or data == 'test':
        return Compose([
            Resize(img_size, img_size),
            Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
            ToTensorV2(),
        ])


train_dataset = CustomDataset(train_imgs, train_labels, transform=get_transforms(data='train'))
val_dataset = CustomDataset(val_imgs, val_labels, transform=get_transforms(data='valid'))

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)
val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=False)

"""## 모델

ResNet50에 LSTM을 연결한 CNN2RNN 모델
"""

class CNN_Encoder(nn.Module):
    def __init__(self, rate):
        super(CNN_Encoder, self).__init__()  
        # all_models = timm.list_models('*resnet*', pretrained=True)        
        # print("models", all_models)
        self.model = timm.create_model('resnet200d', pretrained=vision_pretrain)
        self.fc = nn.Linear(2048, 512)
        self.fc2 = nn.Linear(512, 1)
        self.gap = nn.AdaptiveAvgPool2d(1)

    def forward(self, x):
        x = self.model.forward_features(x)
        # x = x.permute(0,2,3,1)        
        x = self.gap(x)
        x = x.view([-1, x.shape[1]])
        x = nn.ReLU()(self.fc(x))
        x = nn.ReLU()(self.fc2(x))
        return x


model = CNN_Encoder(rate=dropout_rate)
model = model.to(device)


"""## 학습 정의"""

optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)
criterion = nn.L1Loss()
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=eta_min)

"""## 학습"""

loss_plot, val_loss_plot = [], []

for epoch in range(EPOCHS):
    total_loss, total_val_loss = 0, 0
    
    model.train()
    tqdm_dataset = tqdm(enumerate(train_dataloader))    
    for batch, batch_item in tqdm_dataset:
        img = batch_item['img'].to(device)
        label = batch_item['label'].to(device)        

        optimizer.zero_grad()
        with torch.cuda.amp.autocast():
            output = model(img)
            loss = criterion(output, label)
        loss.backward()
        optimizer.step()
        scheduler.step()

        total_loss += loss
        
        tqdm_dataset.set_postfix({
            'Epoch': epoch + 1,
            'Loss': '{:06f}'.format(loss.item()),
            'Total Loss' : '{:06f}'.format(total_loss/(batch+1))
        })
    loss_plot.append(total_loss/(batch+1))
    
    model.eval()
    tqdm_dataset = tqdm(enumerate(val_dataloader))
    for batch, batch_item in tqdm_dataset:
        img = batch_item['img'].to(device)
        label = batch_item['label'].to(device)
        with torch.no_grad():
            output = model(img)
            loss = criterion(output, label)
        total_val_loss += loss
        
        tqdm_dataset.set_postfix({
            'Epoch': epoch + 1,
            'Val Loss': '{:06f}'.format(loss.item()),
            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1))
        })
    val_loss_plot.append(total_val_loss/(batch+1))
    
    if np.min(val_loss_plot) == val_loss_plot[-1]:
        torch.save(model, save_path)
    
    """## 학습 결과"""

    plt.plot(loss_plot, color='blue', label='train_loss')
    plt.plot(val_loss_plot, color='red', label='val_loss')
    plt.xlabel('epoch')
    plt.ylabel('loss(mae)')
    # plt.legend()
    # plt.show()
    plt.grid(True)
    plt.savefig('../output/seed_resnet200_3.png')
    print("Epoch {} min val loss {}".format(epoch + 1, min(val_loss_plot)))



"""## 모델 복원"""

model = torch.load(save_path)
model = tta.ClassificationTTAWrapper(model.to(device),
                                     tta.aliases.ten_crop_transform(img_size, img_size),
                                     merge_mode='mean')

"""## 테스트 데이터 및 제출 양식 로드"""

test = pd.read_csv('../inputs/test.csv')
submission = pd.read_csv('../inputs/sample_submission.csv')

"""## 테스트 데이터 전처리"""

# for idx, row in tqdm(test.iterrows()):
#     file = row['uid']
#     smiles = row['SMILES']
#     m = Chem.MolFromSmiles(smiles)
#     if m != None:
#         img = Draw.MolToImage(m, size=(300,300))
#         img.save(f'../inputs/test_imgs/{file}.png')

"""## 테스트 데이터셋"""

test_imgs = ('../inputs/test_imgs/'+test.uid+'.png').to_numpy()

test_dataset = CustomDataset(imgs=test_imgs, labels=None, mode='test', transform=get_transforms(data='test'))
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=0)

"""## 추론 및 제출"""

def predict(dataset):
    model.eval()
    result = []
    for batch_item in tqdm(dataset):
        img = batch_item['img'].to(device)
        with torch.no_grad():
            output = model(img)
        output = output.cpu().numpy()
        for i in list(output):
            result.extend(i)
        # gap = output[:, 0] - output[:, 1]
        # gap = np.where(gap<0, 0, gap)
        # result.extend(list(gap))
        
    return result

pred = predict(test_dataloader)
print("predict")
submission['ST1_GAP(eV)'] = pred

submission

submission.to_csv('../output/seed_resnet200_3_tta.csv', index=False)
print("create csv")
